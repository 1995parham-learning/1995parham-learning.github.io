# Python

## Class and static methods

<aside>
ğŸ§  *Changed in version 3.9:*Â Class methods can now wrap otherÂ [descriptors](https://docs.python.org/3/glossary.html#term-descriptor)Â such asÂ `[property()](https://docs.python.org/3/library/functions.html#property)`.

</aside>

<aside>
ğŸ¦– *Changed in version 3.10:*Â Class methods now inherit the method attributes (`__module__`,Â `__name__`,Â `__qualname__`,Â `__doc__`Â andÂ `__annotations__`) and have a newÂ `__wrapped__`Â attribute.

</aside>

<aside>
ğŸ”¥ *Changed in version 3.11:*Â Class methods can no longer wrap otherÂ [descriptors](https://docs.python.org/3/glossary.html#term-descriptor)Â such asÂ `[property()](https://docs.python.org/3/library/functions.html#property)`.

</aside>

## Operator

TheÂ `[operator](https://docs.python.org/3/library/operator.html#module-operator)`Â module exports a set of efficient functions corresponding to the intrinsic operators of Python. For example,Â `operator.add(x,Â y)`Â is equivalent to the expressionÂ `x+y`. 

## Bisect

This module provides support for maintaining a list in sorted order without having to sort the list after each insertion. For long lists of items with expensive comparison operations, this can be an improvement over linear searches or frequent resorting.

```python
bisect.**bisect_left**(*a*,Â *x*,Â *lo=0*,Â *hi=len(a)*,Â ***,Â *key=None*)
```

Locate the insertion point forÂ *x*Â inÂ *a*Â to maintain sorted order. The parametersÂ *lo*Â andÂ *hi*Â may be used to specify a subset of the list which should be considered; by default the entire list is used. IfÂ *x*Â is already present inÂ *a*, the insertion point will be before (to the left of) any existing entries. The return value is suitable for use as the first parameter toÂ `list.insert()`Â assuming thatÂ *a*Â is already sorted.
The returned insertion pointÂ *ip*Â partitions the arrayÂ *a*Â into two slices such thatÂ `all(elemÂ <Â xÂ forÂ elemÂ inÂ a[loÂ :Â ip])`Â is true for the left slice andÂ `all(elemÂ >=Â xÂ forÂ elemÂ inÂ a[ipÂ :Â hi])`Â is true for the right slice.
*key*Â specifies aÂ [key function](https://docs.python.org/3/glossary.html#term-key-function)Â of one argument that is used to extract a comparison key from each element in the array. To support searching complex records, the key function is not applied to theÂ *x*Â value.
IfÂ *key*Â isÂ `None`, the elements are compared directly and no key function is called.

```python
bisect.**bisect_right**(*a*,Â *x*,Â *lo=0*,Â *hi=len(a)*,Â ***,Â *key=None*)
bisect.**bisect**(*a*,Â *x*,Â *lo=0*,Â *hi=len(a)*,Â ***,Â *key=None*)
```

Similar toÂ `[bisect_left()](https://docs.python.org/3/library/bisect.html#bisect.bisect_left)`, but returns an insertion point which comes after (to the right of) any existing entries ofÂ *x*Â inÂ *a*.

The returned insertion pointÂ *ip*Â partitions the arrayÂ *a*Â into two slices such thatÂ `all(elemÂ <=Â xÂ forÂ elemÂ inÂ a[loÂ :Â ip])`Â is true for the left slice andÂ `all(elemÂ >Â xÂ forÂ elemÂ inÂ a[ipÂ :Â hi])`Â is true for the right slice.

## Itertools

[itertools â€” Functions creating iterators for efficient looping](https://docs.python.org/3/library/itertools.html)

This module implements a number ofÂ [iterator](https://docs.python.org/3/glossary.html#term-iterator)Â building blocks inspired by constructs from APL, Haskell, and SML. Each has been recast in a form suitable for Python.

The module standardizes a core set of fast, memory efficient tools that are useful by themselves or in combination. Together, they form an â€œiterator algebraâ€ making it possible to construct specialized tools succinctly and efficiently in pure Python.

**Infinite iterators:**

| Iterator | Arguments | Results | Example |
| --- | --- | --- | --- |
| https://docs.python.org/3/library/itertools.html#itertools.count | [start[, step]] | start, start+step, start+2*step, â€¦ | count(10)Â -->Â 10Â 11Â 12Â 13Â 14Â ... |
| https://docs.python.org/3/library/itertools.html#itertools.cycle | p | p0, p1, â€¦ plast, p0, p1, â€¦ | cycle('ABCD')Â -->Â AÂ BÂ CÂ DÂ AÂ BÂ CÂ DÂ ... |
| https://docs.python.org/3/library/itertools.html#itertools.repeat | elem [,n] | elem, elem, elem, â€¦ endlessly or up to n times | repeat(10,Â 3)Â -->Â 10Â 10Â 10 |

**Iterators terminating on the shortest input sequence:**

| Iterator | Arguments | Results | Example |
| --- | --- | --- | --- |
| https://docs.python.org/3/library/itertools.html#itertools.accumulate | p [,func] | p0, p0+p1, p0+p1+p2, â€¦ | accumulate([1,2,3,4,5])Â -->Â 1Â 3Â 6Â 10Â 15 |
| https://docs.python.org/3/library/itertools.html#itertools.batched | p, n | (p0, p1, â€¦, p_n-1), â€¦ | batched('ABCDEFG',Â n=3)Â -->Â ABCÂ DEFÂ G |
| https://docs.python.org/3/library/itertools.html#itertools.chain | p, q, â€¦ | p0, p1, â€¦ plast, q0, q1, â€¦ | chain('ABC',Â 'DEF')Â -->Â AÂ BÂ CÂ DÂ EÂ F |
| https://docs.python.org/3/library/itertools.html#itertools.chain.from_iterable | iterable | p0, p1, â€¦ plast, q0, q1, â€¦ | chain.from_iterable(['ABC',Â 'DEF'])Â -->Â AÂ BÂ CÂ DÂ EÂ F |
| https://docs.python.org/3/library/itertools.html#itertools.compress | data, selectors | (d[0] if s[0]), (d[1] if s[1]), â€¦ | compress('ABCDEF',Â [1,0,1,0,1,1])Â -->Â AÂ CÂ EÂ F |
| https://docs.python.org/3/library/itertools.html#itertools.dropwhile | pred, seq | seq[n], seq[n+1], starting when pred fails | dropwhile(lambdaÂ x:Â x<5,Â [1,4,6,4,1])Â -->Â 6Â 4Â 1 |
| https://docs.python.org/3/library/itertools.html#itertools.filterfalse | pred, seq | elements of seq where pred(elem) is false | filterfalse(lambdaÂ x:Â x%2,Â range(10))Â -->Â 0Â 2Â 4Â 6Â 8 |
| https://docs.python.org/3/library/itertools.html#itertools.groupby | iterable[, key] | sub-iterators grouped by value of key(v) |  |
| https://docs.python.org/3/library/itertools.html#itertools.islice | seq, [start,] stop [, step] | elements from seq[start:stop:step] | islice('ABCDEFG',Â 2,Â None)Â -->Â CÂ DÂ EÂ FÂ G |
| https://docs.python.org/3/library/itertools.html#itertools.pairwise | iterable | (p[0], p[1]), (p[1], p[2]) | pairwise('ABCDEFG')Â -->Â ABÂ BCÂ CDÂ DEÂ EFÂ FG |
| https://docs.python.org/3/library/itertools.html#itertools.starmap | func, seq | func(*seq[0]), func(*seq[1]), â€¦ | starmap(pow,Â [(2,5),Â (3,2),Â (10,3)])Â -->Â 32Â 9Â 1000 |
| https://docs.python.org/3/library/itertools.html#itertools.takewhile | pred, seq | seq[0], seq[1], until pred fails | takewhile(lambdaÂ x:Â x<5,Â [1,4,6,4,1])Â -->Â 1Â 4 |
| https://docs.python.org/3/library/itertools.html#itertools.tee | it, n | it1, it2, â€¦ itn splits one iterator into n |  |
| https://docs.python.org/3/library/itertools.html#itertools.zip_longest | p, q, â€¦ | (p[0], q[0]), (p[1], q[1]), â€¦ | zip_longest('ABCD',Â 'xy',Â fillvalue='-')Â -->Â AxÂ ByÂ C-Â D- |

**Combinatoric iterators:**

| Iterator | Arguments | Results |
| --- | --- | --- |
| https://docs.python.org/3/library/itertools.html#itertools.product | p, q, â€¦ [repeat=1] | cartesian product, equivalent to a nested for-loop |
| https://docs.python.org/3/library/itertools.html#itertools.permutations | p[, r] | r-length tuples, all possible orderings, no repeated elements |
| https://docs.python.org/3/library/itertools.html#itertools.combinations | p, r | r-length tuples, in sorted order, no repeated elements |
| https://docs.python.org/3/library/itertools.html#itertools.combinations_with_replacement | p, r | r-length tuples, in sorted order, with repeated elements |

### Batched

```python
itertools.**batched**(*iterable*,Â *n*)
```

Batch data from theÂ *iterable*Â into tuples of lengthÂ *n*.

The last batch may be shorter thanÂ *n*. Loops over the input iterable and accumulates data into tuples up to sizeÂ *n*. The input is consumed lazily, just enough to fill a batch. The result is yielded as soon as the batch is full or when the input iterable is exhausted:

```python

**>>>** flattened_data = ['roses', 'red', 'violets', 'blue', 'sugar', 'sweet']
**>>>** unflattened = list(batched(flattened_data, 2))
**>>>** unflattened
[('roses', 'red'), ('violets', 'blue'), ('sugar', 'sweet')]

**>>> for** batch **in** batched('ABCDEFG', 3):
**...**     print(batch)
**...**('A', 'B', 'C')
('D', 'E', 'F')
('G',)
```

## Iterables and Iterators

Pythonâ€™sÂ **iterators**Â andÂ **iterables**Â are two different but related tools that come in handy when you need to iterate over a data stream or container. Iterators power and control the iteration process, while iterables typically hold data that you want to iterate over one value at a time.

## Formatted Strings

AÂ *formatted string literal*Â orÂ *f-string*Â is a string literal that is prefixed withÂ `'f'`Â orÂ `'F'`. These strings may contain replacement fields, which are expressions delimited by curly bracesÂ `{}`. While other string literals always have a constant value, formatted strings are really expressions evaluated at run time.

The parts of the string outside curly braces are treated literally, except that any doubled curly bracesÂ `'{{'`Â orÂ `'}}'`Â are replaced with the corresponding single curly brace. A single opening curly bracketÂ `'{'`Â marks a replacement field, which starts with a Python expression. To display both the expression text and its value after evaluation, (useful in debugging), an equal signÂ `'='`Â may be added after the expression. A conversion field, introduced by an exclamation pointÂ `'!'`Â may follow. A format specifier may also be appended, introduced by a colonÂ `':'`. A replacement field ends with a closing curly bracketÂ `'}'`.

If a conversion is specified, the result of evaluating the expression is converted before formatting. ConversionÂ `'!s'`Â callsÂ `[str()](https://docs.python.org/3/library/stdtypes.html#str)`Â on the result,Â `'!r'`Â callsÂ `[repr()](https://docs.python.org/3/library/functions.html#repr)`, andÂ `'!a'`Â callsÂ `[ascii()](https://docs.python.org/3/library/functions.html#ascii)`.

The result is then formatted using theÂ `[format()](https://docs.python.org/3/library/functions.html#format)`Â protocol. The format specifier is passed to theÂ `[__format__()](https://docs.python.org/3/reference/datamodel.html#object.__format__)`Â method of the expression or conversion result. An empty string is passed when the format specifier is omitted. The formatted result is then included in the final value of the whole string.

```python
width = 10
precision = 4
value = decimal.Decimal("12.34567")
f"result: {value:{width}.{precision}}"  # nested fields
```

<aside>
ğŸ”§ *Changed in version 3.12:*Â Prior to Python 3.12, reuse of the same quoting type of the outer f-string inside a replacement field was not possible.

</aside>

Backslashes are also allowed in replacement fields and are evaluated the same way as in any other context:

```python
a = ["a", "b", "c"]
print(f"List a contains:\n{"\n".join(a)}")
```

<aside>
ğŸ”§ *Changed in version 3.12:*Â Prior to Python 3.12, backslashes were not permitted inside an f-string replacement field.

</aside>

## Configuration ğŸ”§

I love the way we can configure Golang applications **WITH TYPES**, but this library is in Python, and seems nice to me for doing the same in Python.

[https://github.com/dynaconf/dynaconf](https://github.com/dynaconf/dynaconf)

## HTTP Frameworks ğŸŒ

Sometimes I donâ€™t want to set up the giant Django so, I have these options. Sanic and FastAPI both are asynchronous and says they have good performance.

### Sanic

**Simple and lightweight**

Intuitive API with smart defaults and no bloat allows you to get straight to work building your app.

**Unopinionated and flexible**

Build the way you want to build without letting your tooling constrain you.

**Performant and scalable**

Built from the ground up with speed and scalability as a main concern. It is ready to power web applications big and small.

**Production ready**

Out of the box, it comes bundled with a web server ready to power your web applications.

**Trusted by millions**

Sanic is one of the overall most popular frameworks on PyPI, and the top async enabled framework

**Community driven**

The project is maintained and run by the community for the community.

- After installing, Sanic has all the tools you need for a scalable, production-grade serverâ€”out of the box!
- Running Sanic with TLS enabled is as simple as passing it the file pathsâ€¦
- Up and running with websockets in no time using theÂ [websockets](https://websockets.readthedocs.io/)Â package.
- Serving static files is of course intuitive and easy. Just name an endpoint and either a file or directory that should be served.
- Beginning or ending a route with functionality is as simple as adding a decorator.
- Raising errors will intuitively result in proper HTTP errors:
- Check in on your live, running applications (whether local or remote).
- In addition to the tools that Sanic comes with, the officially supportedÂ [Sanic Extensions](https://sanic.dev/en/plugins/sanic-ext/getting-started.html)Â provides lots of extra goodies to make development easier.
    - **CORS**Â protection
    - Template rendering withÂ **Jinja**
    - **Dependency injection**Â into route handlers
    - OpenAPI documentation withÂ **Redoc**Â and/orÂ **Swagger**
    - Predefined, endpoint-specific responseÂ **serializers**
    - Request query arguments and body inputÂ **validation**
    - **Auto create**Â HEAD, OPTIONS, and TRACE endpoints
    - LiveÂ **health monitor**

[Sanic User Guide - The lightning-fast asynchronous Python web framework](https://sanic.dev/en/)

Dependency injection is a method to add arguments to a route handler based upon the defined function signature. Specifically, it looks at theÂ **type annotations**Â of the arguments in the handler. This can be useful in a number of cases like:

[Sanic User Guide - Sanic Extensions - Dependency Injection](https://sanic.dev/en/plugins/sanic-ext/injection.html#getting-started)

### Flask

[Welcome to Flask â€” Flask Documentation (3.0.x)](https://flask.palletsprojects.com/en/3.0.x/)

### FastAPI

[FastAPI](https://fastapi.tiangolo.com/)

## HTTP Client ğŸŒ

- https://github.com/psf/requests
- https://github.com/encode/httpx

## Django ğŸ¦–

The Django documentation which is the best source for learning and reading about it.

[Django](https://docs.djangoproject.com/en)

Django has built-in support for GIS data. You can find more about it here (for Django 4.1):

[Django](https://docs.djangoproject.com/en/5.0/ref/contrib/gis/)

Writing REST API in a Django application using Django REST Framework is awesome, following links are the important concepts of the DRF (Django REST Framework):

[Home - Django REST framework](https://www.django-rest-framework.org/)

- [https://www.django-rest-framework.org/api-guide/serializers/](https://www.django-rest-framework.org/api-guide/serializers/)
- [https://www.django-rest-framework.org/api-guide/fields](https://www.django-rest-framework.org/api-guide/fields)
- [https://www.django-rest-framework.org/api-guide/parsers/](https://www.django-rest-framework.org/api-guide/parsers/)
- [https://www.django-rest-framework.org/api-guide/views/](https://www.django-rest-framework.org/api-guide/views/)
- [https://www.django-rest-framework.org/api-guide/viewsets/](https://www.django-rest-framework.org/api-guide/viewsets/)
- [https://www.django-rest-framework.org/api-guide/generic-views/](https://www.django-rest-framework.org/api-guide/generic-views/)
- [https://www.django-rest-framework.org/api-guide/filtering/](https://www.django-rest-framework.org/api-guide/filtering/)

Sometimes it is better in DRF to read its code because its documentation is not complete:

- [https://github.com/encode/django-rest-framework](https://github.com/encode/django-rest-framework)

Semi-automatic swagger documentation for the REST APIs:

- [https://github.com/tfranzel/drf-spectacula](https://github.com/tfranzel/drf-spectacular)

Using data-classes to define request and response in Django REST Framework:

[https://github.com/oxan/djangorestframework-dataclasses](https://github.com/oxan/djangorestframework-dataclasses)

Having reusable filters for models in Django REST Framework with Django-filter. These filters help you to write viewsets easier and give client developers vast choices in getting the data.

[django-filter 23.5 documentation](https://django-filter.readthedocs.io/en/main/)

There are cases in which you already have the database and want to describe it using Django models:

```bash
python manage.py inspectdb
```

## Tests

In python, you need a library for testing:

[pytest: helps you write better programs â€” pytest documentation](https://docs.pytest.org/en/stable/index.html)

But in Django you donâ€™t need anything and Django already has what you need.

## Standard CLI ğŸ’¾

[Welcome to Click â€” Click Documentation (8.1.x)](https://click.palletsprojects.com/)

## Console UIs ğŸ’…

[https://github.com/Textualize/rich](https://github.com/Textualize/rich)

[https://github.com/sepandhaghighi/art](https://github.com/sepandhaghighi/art)

## Pandas ğŸ¼

The best way for working with data, doing math and statistics over it, etc. is using Pandas:

[API reference â€” pandas 2.2.0 documentation](https://pandas.pydata.org/docs/reference/index.html)

Using it for reading/writing CSV is a better way than any other console application because you can actually do the query things after the reading phase.

## GIS

- [https://shapely.readthedocs.io/en/stable/](https://shapely.readthedocs.io/en/stable/)
- [https://geopandas.org/en/stable/](https://geopandas.org/en/stable/)

## Typing

The function below takes and returns a string and is annotated as follows:

```python
def greeting(name: str) -> str:
    return 'Hello ' + name
```

In the functionÂ `greeting`, the argumentÂ `name`Â is expected to be of typeÂ `[str](https://docs.python.org/3/library/stdtypes.html#str)`Â and the return typeÂ `[str](https://docs.python.org/3/library/stdtypes.html#str)`. Subtypes are accepted as arguments.

### Type aliases

A type alias is defined using theÂ `[type](https://docs.python.org/3/reference/simple_stmts.html#type)`Â statement, which creates an instance ofÂ `[TypeAliasType](https://docs.python.org/3/library/typing.html#typing.TypeAliasType)`. In this example,Â `Vector`Â andÂ `list[float]`Â will be treated equivalently by static type checkers:

```python
type Vector = list[float]

def scale(scalar: float, vector: Vector) -> Vector:
    return [scalar * num for num in vector]

# passes type checking; a list of floats qualifies as a Vector.
new_vector = scale(2.0, [1.0, -4.2, 5.4])
```

Type aliases are useful for simplifying complex type signatures.

### Annotating callable objects

Functions â€“ or otherÂ [callable](https://docs.python.org/3/glossary.html#term-callable)Â objects â€“ can be annotated usingÂ `[collections.abc.Callable](https://docs.python.org/3/library/collections.abc.html#collections.abc.Callable)`Â orÂ `[typing.Callable](https://docs.python.org/3/library/typing.html#typing.Callable)`.Â `Callable[[int],Â str]`Â signifies a function that takes a single parameter of typeÂ `[int](https://docs.python.org/3/library/functions.html#int)`Â and returns aÂ `[str](https://docs.python.org/3/library/stdtypes.html#str)`.

```python
from collections.abc import Callable, Awaitable

def feeder(get_next_item: Callable[[], str]) -> None:
    ...  # Body

def async_query(on_success: Callable[[int], None],
                on_error: Callable[[int, Exception], None]) -> None:
    ...  # Body

async def on_update(value: str) -> None:
    ...  # Body

callback: Callable[[str], Awaitable[None]] = on_update
```

The subscription syntax must always be used with exactly two values: the argument list and the return type. The argument list must be a list of types, aÂ `[ParamSpec](https://docs.python.org/3/library/typing.html#typing.ParamSpec)`,Â `[Concatenate](https://docs.python.org/3/library/typing.html#typing.Concatenate)`, or an ellipsis. The return type must be a single type.

If a literal ellipsisÂ `...`Â is given as the argument list, it indicates that a callable with any arbitrary parameter list would be acceptable:

```python
def concat(x: str, y: str) -> str:
return x + y

x: Callable[..., str]
x = str# OKx = concat# Also OK
```

<aside>
âš ï¸ `Callable`Â cannot express complex signatures such as functions that take a variadic number of arguments,Â [overloaded functions](https://docs.python.org/3/library/typing.html#overload), or functions that have keyword-only parameters. However, these signatures can be expressed by defining aÂ `[Protocol](https://docs.python.org/3/library/typing.html#typing.Protocol)`Â class with aÂ `[__call__()](https://docs.python.org/3/reference/datamodel.html#object.__call__)`Â method.

</aside>

```python
from collections.abc import Iterable
from typing import Protocol

class Combiner(Protocol):
    def __call__(self, *vals: bytes, maxlen: int | None = None) -> list[bytes]: ...

def batch_proc(data: Iterable[bytes], cb_results: Combiner) -> bytes:
    for item in data:
        ...

def good_cb(*vals: bytes, maxlen: int | None = None) -> list[bytes]:
    ...
def bad_cb(*vals: bytes, maxitems: int | None) -> list[bytes]:
    ...

batch_proc([], good_cb)  # OK
batch_proc([], bad_cb)   # Error! Argument 2 has incompatible type because of
                         # different name and kind in the callback
```

### Generics

Since type information about objects kept in containers cannot be statically inferred in a generic way, many container classes in the standard library support subscription to denote the expected types of container elements.

```python
from collections.abc import Mapping, Sequence

class Employee: ...

# Sequence[Employee] indicates that all elements in the sequence
# must be instances of "Employee".
# Mapping[str, str] indicates that all keys and all values in the mapping
# must be strings.
def notify_by_email(employees: Sequence[Employee],
                    overrides: Mapping[str, str]) -> None: ...
```

Generic functions and classes can be parameterized by usingÂ [type parameter syntax](https://docs.python.org/3/reference/compound_stmts.html#type-params):

```python
from collections.abc import Sequence

def first[T](l: Sequence[T]) -> T:  # Function is generic over the TypeVar "T"
    return l[0]
```

<aside>
âš ï¸ *Changed in version 3.12:*Â Syntactic support for generics is new in Python 3.12.

</aside>

For most containers in Python, the typing system assumes that all elements in the container will be of the same type. `[list](https://docs.python.org/3/library/stdtypes.html#list)`Â only accepts one type argument. `[Mapping](https://docs.python.org/3/library/collections.abc.html#collections.abc.Mapping)`Â only accepts two type arguments: the first indicates the type of the keys, and the second indicates the type of the values.

```python
from collections.abc import Mapping

# Type checker will infer that all elements in ``x`` are meant to be ints
x: list[int] = []

# Type checker error: ``list`` only accepts a single type argument:
y: list[int, str] = [1, 'foo']

# Type checker will infer that all keys in ``z`` are meant to be strings,
# and that all values in ``z`` are meant to be either strings or ints
z: Mapping[str, str | int] = {}
```

Unlike most other Python containers, however, it is common in idiomatic Python code for tuples to have elements which are not all of the same type. For this reason, tuples are special-cased in Pythonâ€™s typing system.Â `[tuple](https://docs.python.org/3/library/stdtypes.html#tuple)`Â acceptsÂ *any number*Â of type arguments:

```python
# OK: ``x`` is assigned to a tuple of length 1 where the sole element is an int
x: tuple[int] = (5,)

# OK: ``y`` is assigned to a tuple of length 2;
# element 1 is an int, element 2 is a str
y: tuple[int, str] = (5, "foo")

# Error: the type annotation indicates a tuple of length 1,
# but ``z`` has been assigned to a tuple of length 3
z: tuple[int] = (1, 2, 3)
```

To denote a tuple which could be ofÂ *any*Â length, and in which all elements are of the same typeÂ `T`, useÂ `tuple[T,Â ...]`. To denote an empty tuple, useÂ `tuple[()]`. Using plainÂ `tuple`Â as an annotation is equivalent to usingÂ `tuple[Any,Â ...]` .

### **The type of class objects**

A variable annotated withÂ `C`Â may accept a value of typeÂ `C`. In contrast, a variable annotated withÂ `type[C]`Â (orÂ `[typing.Type[C]](https://docs.python.org/3/library/typing.html#typing.Type)`) may accept values that are classes themselves â€“ specifically, it will accept theÂ *class object*Â ofÂ `C`.

```python
a = 3         # Has type ``int``
b = int       # Has type ``type[int]``
c = type(a)   # Also has type ``type[int]``
```

Note thatÂ `type[C]`Â is covariant:

<aside>
ğŸ§  *Covariance and contravariance are terms that refer to the ability to use a more derived type (more specific) or a less derived type (less specific) than originally specified*

</aside>

```python
class User: ...
class ProUser(User): ...
class TeamUser(User): ...

def make_new_user(user_class: type[User]) -> User:
    # ...
    return user_class()

make_new_user(User)      # OK
make_new_user(ProUser)   # Also OK: ``type[ProUser]`` is a subtype of ``type[User]``
make_new_user(TeamUser)  # Still fine
make_new_user(User())    # Error: expected ``type[User]`` but got ``User``
make_new_user(int)       # Error: ``type[int]`` is not a subtype of ``type[User]``
```

The only legal parameters forÂ `[type](https://docs.python.org/3/library/functions.html#type)`Â are classes,Â `[Any](https://docs.python.org/3/library/typing.html#typing.Any)`,Â [type variables](https://docs.python.org/3/library/typing.html#generics), and unions of any of these types.

### Packages

We love types even in python ğŸ’˜

[https://github.com/typeddjango/djangorestframework-stubs](https://github.com/typeddjango/djangorestframework-stubs)

[https://github.com/typeddjango/django-stubs](https://github.com/typeddjango/django-stubs)

[https://github.com/typeddjango/awesome-python-typing](https://github.com/typeddjango/awesome-python-typing)

[Typing (numpy.typing) â€” NumPy v1.26 Manual](https://numpy.org/doc/stable/reference/typing.html)

## Images

In python, you can even manipulate images.

- [https://pillow.readthedocs.io/en/stable/index.html](https://pillow.readthedocs.io/en/stable/index.html)

## [Pydantic](https://docs.pydantic.dev/latest/)

[Welcome to Pydantic - Pydantic](https://docs.pydantic.dev/latest/)

One of the primary ways of defining schema in Pydantic is via models. Models are simply classes which inherit fromÂ `[pydantic.BaseModel](https://docs.pydantic.dev/latest/api/base_model/#pydantic.BaseModel)`Â and define fields as annotated attributes.

You can think of models as similar to structs in languages like C, or as the requirements of a single endpoint in an API.

Models share many similarities with Python's dataclasses, but have been designed with some subtle-yet-important differences that streamline certain workflows related to validation, serialization, and JSON schema generation.

Untrusted data can be passed to a model and, after parsing and validation, Pydantic guarantees that the fields of the resultant model instance will conform to the field types defined on the model.

Beyond accessing model attributes directly via their field names (e.g.Â `model.foobar`), models can be converted, dumped, serialized, and exported in a number of ways.

TheÂ `[Field](https://docs.pydantic.dev/latest/api/fields/#pydantic.fields.Field)`Â function is used to customize and add metadata to fields of models.

### Examples

[https://github.com/1995parham-goodies/opta-client](https://github.com/1995parham-goodies/opta-client)

## Asynchronous

### **Asynchronous I/O**

[asyncio â€” Asynchronous I/O](https://docs.python.org/3/library/asyncio.html)

asyncio is used as a foundation for multiple Python asynchronous frameworks that provide high-performance network and web-servers, database connection libraries, distributed task queues, etc.

Runners are built on top of anÂ [event loop](https://docs.python.org/3/library/asyncio-eventloop.html#asyncio-event-loop)Â with the aim to simplify async code usage for common wide-spread scenarios.

```python
asyncio.run(coro, *, debug=None, loop_factory=None)
```

This function runs the passed coroutine, taking care of managing the asyncio event loop,Â *finalizing asynchronous generators*, and closing the executor.

This function cannot be called when another asyncio event loop is running in the same thread.

IfÂ *debug*Â isÂ `True`, the event loop will be run in debug mode.Â `False`Â disables debug mode explicitly.Â `None`Â is used to respect the globalÂ [Debug Mode](https://docs.python.org/3/library/asyncio-dev.html#asyncio-debug-mode)Â settings.

IfÂ *loop_factory*Â is notÂ `None`, it is used to create a new event loop; otherwiseÂ `[asyncio.new_event_loop()](https://docs.python.org/3/library/asyncio-eventloop.html#asyncio.new_event_loop)`Â is used. The loop is closed at the end. This function should be used as a main entry point for asyncio programs, and should ideally only be called once. It is recommended to useÂ *loop_factory*Â to configure the event loop instead of policies.

```python
async def main():
    await asyncio.sleep(1)
    print('hello')

asyncio.run(main())
```

```python
class asyncio.Runner(*, debug=None, loop_factory=None)
```

A context manager that simplifiesÂ *multiple*Â async function calls in the same context.

Sometimes several top-level async functions should be called in the sameÂ [event loop](https://docs.python.org/3/library/asyncio-eventloop.html#asyncio-event-loop)Â andÂ `[contextvars.Context](https://docs.python.org/3/library/contextvars.html#contextvars.Context)`.

IfÂ *debug*Â isÂ `True`, the event loop will be run in debug mode.Â `False`Â disables debug mode explicitly.Â `None`Â is used to respect the globalÂ [Debug Mode](https://docs.python.org/3/library/asyncio-dev.html#asyncio-debug-mode)Â settings.

*loop_factory*Â could be used for overriding the loop creation. It is the responsibility of theÂ *loop_factory*Â to set the created loop as the current one. By defaultÂ `[asyncio.new_event_loop()](https://docs.python.org/3/library/asyncio-eventloop.html#asyncio.new_event_loop)`Â is used and set as current event loop withÂ `[asyncio.set_event_loop()](https://docs.python.org/3/library/asyncio-eventloop.html#asyncio.set_event_loop)`Â ifÂ *loop_factory*Â isÂ `None`.

Basically,Â `[asyncio.run()](https://docs.python.org/3/library/asyncio-runner.html#asyncio.run)`Â example can be rewritten with the runner usage:

```python
async def main():
    await asyncio.sleep(1)
    print('hello')

with asyncio.Runner() as runner:
    runner.run(main())
```

```python
**run**(*coro*,Â ***,Â *context=None*)
```

Run aÂ [coroutine](https://docs.python.org/3/glossary.html#term-coroutine)Â *coro*Â in the embedded loop. Return the coroutineâ€™s result or raise its exception. An optional keyword-onlyÂ *context*Â argument allows specifying a customÂ `[contextvars.Context](https://docs.python.org/3/library/contextvars.html#contextvars.Context)`Â for theÂ *coro*Â to run in. The runnerâ€™s default context is used ifÂ `None`. This function cannot be called when another asyncio event loop is running in the same thread.

```python
**close**()
```

Close the runner. Finalize asynchronous generators, shutdown default executor, close the event loop and release embeddedÂ `[contextvars.Context](https://docs.python.org/3/library/contextvars.html#contextvars.Context)`.

```python
**get_loop**()
```

Return the event loop associated with the runner instance.

[Coroutines](https://docs.python.org/3/glossary.html#term-coroutine)Â declared with the async/await syntax is the preferred way of writing asyncio applications. To actually run a coroutine, asyncio provides the following mechanisms:

- TheÂ `[asyncio.run()](https://docs.python.org/3/library/asyncio-runner.html#asyncio.run)`Â function to run the top-level entry point â€œmain()â€ function.
- Awaiting on a coroutine. The following snippet of code will print â€œhelloâ€ after waiting for 1 second, and then print â€œworldâ€ after waiting forÂ *another*Â 2 seconds:
    
    ```python
    import asyncio
    import time
    
    async def say_after(delay, what):
        await asyncio.sleep(delay)
        print(what)
    
    async def main():
        print(f"started at {time.strftime('%X')}")
    
        await say_after(1, 'hello')
        await say_after(2, 'world')
    
        print(f"finished at {time.strftime('%X')}")
    
    asyncio.run(main())
    ```
    
- TheÂ `[asyncio.create_task()](https://docs.python.org/3/library/asyncio-task.html#asyncio.create_task)`Â function to run coroutines concurrently as asyncioÂ `[Tasks](https://docs.python.org/3/library/asyncio-task.html#asyncio.Task)`.
    
    ```python
    async def main():
        task1 = asyncio.create_task(
            say_after(1, 'hello'))
    
        task2 = asyncio.create_task(
            say_after(2, 'world'))
    
        print(f"started at {time.strftime('%X')}")
    
        # Wait until both tasks are completed (should take
        # around 2 seconds.)
        # They ran with create_task and here we only wait
        # for their results.
        await task1
        await task2
    
        print(f"finished at {time.strftime('%X')}")
    ```
    
    TheÂ `[asyncio.TaskGroup](https://docs.python.org/3/library/asyncio-task.html#asyncio.TaskGroup)`Â class provides a more modern alternative toÂ `[create_task()](https://docs.python.org/3/library/asyncio-task.html#asyncio.create_task)`. Using this API, the last example becomes:
    
    ```python
    async def main():
        async with asyncio.TaskGroup() as tg:
            task1 = tg.create_task(
                say_after(1, 'hello'))
    
            task2 = tg.create_task(
                say_after(2, 'world'))
    
            print(f"started at {time.strftime('%X')}")
    
        # The await is implicit when the context manager exits.
    
        print(f"finished at {time.strftime('%X')}")
    ```
    

**Awaitables**

We say that an object is anÂ **awaitable**Â object if it can be used in anÂ `[await](https://docs.python.org/3/reference/expressions.html#await)`Â expression. Many asyncio APIs are designed to accept awaitables.

There are three main types ofÂ *awaitable*Â objects:Â **coroutines**,Â **Tasks**, andÂ **Futures**.

<aside>
âš ï¸ AÂ *coroutine function*: anÂ `[asyncÂ def](https://docs.python.org/3/reference/compound_stmts.html#async-def)`Â function.
AÂ *coroutine object*: an object returned by calling aÂ *coroutine function*.

</aside>

<aside>
ğŸ”¥ *Tasks*Â are used to schedule coroutinesÂ *concurrently*.

</aside>

**[Running Tasks Concurrently](https://docs.python.org/3/library/asyncio-task.html#id8)**

```python
awaitable asyncio.gather(*aws, return_exceptions=False)
```

<aside>
ğŸš§ A new alternative to create and run tasks concurrently and wait for their completion isÂ `[asyncio.TaskGroup](https://docs.python.org/3/library/asyncio-task.html#asyncio.TaskGroup)`.Â *TaskGroup*Â provides stronger safety guarantees thanÂ *gather*Â for scheduling a nesting of subtasks: if a task (or a subtask, a task scheduled by a task) raises an exception,Â *TaskGroup*Â will, whileÂ *gather*Â will not, cancel the remaining scheduled tasks).

</aside>

[**Task Groups**](https://docs.python.org/3/library/asyncio-task.html#id6)

**Task groups** combine a task creation API with a convenient and reliable way to wait for all tasks in the group to finish.

**[Eager Task Factory](https://docs.python.org/3/library/asyncio-task.html#id9)**

<aside>
ğŸ¼ Immediate execution of the coroutine is a semantic change. If the coroutine returns or raises, the task is never scheduled to the event loop. If the coroutine execution blocks, the task is scheduled to the event loop. This change may introduce behavior changes to existing applications. For example, the applicationâ€™s task execution order is likely to change.

</aside>

### **AIOfiles**

**aiofiles**Â is an Apache2 licensed library, written in Python, for handling local disk files in asyncio applications.

[https://github.com/Tinche/aiofiles](https://github.com/Tinche/aiofiles)

### HTTPX

[HTTPX](https://www.python-httpx.org/)

HTTPX is a fully featured HTTP client for Python 3, which provides sync and async APIs, and support for both HTTP/1.1 and HTTP/2.

### **AIOHTTP**

[Welcome to AIOHTTP â€” aiohttp 3.9.3 documentation](https://docs.aiohttp.org/en/stable/)

**Key features:**

- Supports bothÂ [Client](https://docs.aiohttp.org/en/stable/client.html#aiohttp-client)Â andÂ [HTTP Server](https://docs.aiohttp.org/en/stable/web.html#aiohttp-web).
- Supports bothÂ [Server WebSockets](https://docs.aiohttp.org/en/stable/web_quickstart.html#aiohttp-web-websockets)Â andÂ [Client WebSockets](https://docs.aiohttp.org/en/stable/client_quickstart.html#aiohttp-client-websockets)Â out-of-the-box without the Callback Hell.
- Web-server hasÂ [Middlewares](https://docs.aiohttp.org/en/stable/web_advanced.html#aiohttp-web-middlewares),Â [Signals](https://docs.aiohttp.org/en/stable/web_advanced.html#aiohttp-web-signals)Â and pluggable routing.

```python
import aiohttp
import asyncio

async def main():
    async with aiohttp.ClientSession() as session:
        async with session.get('http://python.org') as response:
            print("Status:", response.status)
            print("Content-type:", response.headers['content-type'])
            html = await response.text()
            print("Body:", html[:15], "...")

asyncio.run(main())
```

Now, we have aÂ **`[ClientSession](https://docs.aiohttp.org/en/stable/client_reference.html#aiohttp.ClientSession)`**Â calledÂ `session`Â and aÂ **`[ClientResponse](https://docs.aiohttp.org/en/stable/client_reference.html#aiohttp.ClientResponse)`**Â object calledÂ `resp`. We can get all the information we need from the response. The mandatory parameter ofÂ **`[ClientSession.get()](https://docs.aiohttp.org/en/stable/client_reference.html#aiohttp.ClientSession.get)`**Â coroutine is an HTTPÂ *url*Â (**`[str](https://docs.python.org/3/library/stdtypes.html#str)`**Â or class:yarl.URLÂ instance).

<aside>
ğŸ’¡ **Donâ€™t create a session per request**. Most likely you need a session per application which performs all requests together.

More complex cases may require a session per site, e.g. one for Github and other one for Facebook APIs. Anyway making a session for every request is aÂ **very bad**Â idea.

A session contains a connection pool inside. Connection reusage and keep-alive (both are on by default) may speed up total performance.

</aside>

A session context manager usage is not mandatory butÂ `awaitÂ session.close()`Â method should be called in this case.

**Streaming Response Content**

While methodsÂ **`[read()](https://docs.aiohttp.org/en/stable/client_reference.html#aiohttp.ClientResponse.read)`**,Â **`[json()](https://docs.aiohttp.org/en/stable/client_reference.html#aiohttp.ClientResponse.json)`**Â andÂ **`[text()](https://docs.aiohttp.org/en/stable/client_reference.html#aiohttp.ClientResponse.text)`**Â are very convenient you should use them carefully. All these methods load the whole response in memory. For example if you want to download several gigabyte sized files, these methods will load all the data in memory. Instead you can use theÂ **`[content](https://docs.aiohttp.org/en/stable/client_reference.html#aiohttp.ClientResponse.content)`**Â attribute. It is an instance of theÂ **`[aiohttp.StreamReader](https://docs.aiohttp.org/en/stable/streams.html#aiohttp.StreamReader)`**Â class. TheÂ `gzip`Â andÂ `deflate`Â transfer-encodings are automatically decoded for you:

```python
async with session.get(*'https://api.github.com/events'*) as resp:
    await resp.content.read(10)
```

In general, however, you should use a pattern like this to save what is being streamed to a file:

```python
with open(filename, *'wb'*) as fd:
    async for chunk in resp.content.iter_chunked(chunk_size):
        fd.write(chunk)
```

It is not possible to useÂ **`[read()](https://docs.aiohttp.org/en/stable/client_reference.html#aiohttp.ClientResponse.read)`**,Â **`[json()](https://docs.aiohttp.org/en/stable/client_reference.html#aiohttp.ClientResponse.json)`**Â andÂ **`[text()](https://docs.aiohttp.org/en/stable/client_reference.html#aiohttp.ClientResponse.text)`**Â after explicit reading fromÂ **`[content](https://docs.aiohttp.org/en/stable/client_reference.html#aiohttp.ClientResponse.content)`**.