> [!note]
> Consistent hashing evenly distributes cache keys across shards, even if some of the shards crash or become unavailable.

## Basic technique

In the problem of load balancing, for example, when a BLOB has to be assigned to one of $n$ servers on a cluster, a standard hash function could be used in such a way that we calculate the hash value for that BLOB, assuming the resultant value of the hash is $\beta$, we perform modular operation with the number of servers ($n$) to determine the server in which we can place the BLOB: $\sigma = \beta \ n$ ; hence the BLOB will be placed in the server whose server ID ![{\displaystyle {\text{server ID}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/1536bfe5827e3bd28f0c1cf3524d4078ca7ac62c) is successor of Î¶ ![{\displaystyle \zeta }](https://wikimedia.org/api/rest_v1/media/math/render/svg/d5c3916703cae7938143d38865f78f27faadd4ae) in this case. However, when a server is added or removed during outage or scaling (when n ![{\displaystyle n}](https://wikimedia.org/api/rest_v1/media/math/render/svg/a601995d55609f2d9f5e233e36fbe9ea26011b3b) changes), all the BLOBs in every server should be reassigned and moved due to [rehashing](https://en.wikipedia.org/wiki/Hash_table#Dynamic_resizing "Hash table"), but this operation is expensive.